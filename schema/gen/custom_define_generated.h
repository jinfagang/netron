// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_CUSTOMDEFINE_WNN_H_
#define FLATBUFFERS_GENERATED_CUSTOMDEFINE_WNN_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 2 &&
              FLATBUFFERS_VERSION_MINOR == 0 &&
              FLATBUFFERS_VERSION_REVISION == 6,
             "Non-compatible flatbuffers version included");

#include "tensor_generated.h"
#include "type_generated.h"

namespace wnn {

struct Normalize;
struct NormalizeBuilder;
struct NormalizeT;

struct FilmLPN;
struct FilmLPNBuilder;
struct FilmLPNT;

struct Cubic;
struct CubicBuilder;
struct CubicT;

struct MultiHeadAttention;
struct MultiHeadAttentionBuilder;
struct MultiHeadAttentionT;

inline const flatbuffers::TypeTable *NormalizeTypeTable();

inline const flatbuffers::TypeTable *FilmLPNTypeTable();

inline const flatbuffers::TypeTable *CubicTypeTable();

inline const flatbuffers::TypeTable *MultiHeadAttentionTypeTable();

enum ImageFormatType : int32_t {
  ImageFormatType_RGBA = 0,
  ImageFormatType_RGB = 1,
  ImageFormatType_BGR = 2,
  ImageFormatType_GRAY = 3,
  ImageFormatType_YUV = 4,
  ImageFormatType_HSV = 5,
  ImageFormatType_MIN = ImageFormatType_RGBA,
  ImageFormatType_MAX = ImageFormatType_HSV
};

inline const ImageFormatType (&EnumValuesImageFormatType())[6] {
  static const ImageFormatType values[] = {
    ImageFormatType_RGBA,
    ImageFormatType_RGB,
    ImageFormatType_BGR,
    ImageFormatType_GRAY,
    ImageFormatType_YUV,
    ImageFormatType_HSV
  };
  return values;
}

inline const char * const *EnumNamesImageFormatType() {
  static const char * const names[7] = {
    "RGBA",
    "RGB",
    "BGR",
    "GRAY",
    "YUV",
    "HSV",
    nullptr
  };
  return names;
}

inline const char *EnumNameImageFormatType(ImageFormatType e) {
  if (flatbuffers::IsOutRange(e, ImageFormatType_RGBA, ImageFormatType_HSV)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesImageFormatType()[index];
}

enum FilterType : int8_t {
  FilterType_NEAREST = 0,
  FilterType_BILINEAR = 1,
  FilterType_BICUBIC = 2,
  FilterType_MIN = FilterType_NEAREST,
  FilterType_MAX = FilterType_BICUBIC
};

inline const FilterType (&EnumValuesFilterType())[3] {
  static const FilterType values[] = {
    FilterType_NEAREST,
    FilterType_BILINEAR,
    FilterType_BICUBIC
  };
  return values;
}

inline const char * const *EnumNamesFilterType() {
  static const char * const names[4] = {
    "NEAREST",
    "BILINEAR",
    "BICUBIC",
    nullptr
  };
  return names;
}

inline const char *EnumNameFilterType(FilterType e) {
  if (flatbuffers::IsOutRange(e, FilterType_NEAREST, FilterType_BICUBIC)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesFilterType()[index];
}

struct NormalizeT : public flatbuffers::NativeTable {
  typedef Normalize TableType;
  std::vector<float> means{};
  std::vector<float> stds{};
  bool denormalize = false;
  float epsilon = 0.00001f;
};

struct Normalize FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NormalizeT NativeTableType;
  typedef NormalizeBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NormalizeTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MEANS = 4,
    VT_STDS = 6,
    VT_DENORMALIZE = 8,
    VT_EPSILON = 10
  };
  const flatbuffers::Vector<float> *means() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_MEANS);
  }
  const flatbuffers::Vector<float> *stds() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_STDS);
  }
  bool denormalize() const {
    return GetField<uint8_t>(VT_DENORMALIZE, 0) != 0;
  }
  float epsilon() const {
    return GetField<float>(VT_EPSILON, 0.00001f);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_MEANS) &&
           verifier.VerifyVector(means()) &&
           VerifyOffset(verifier, VT_STDS) &&
           verifier.VerifyVector(stds()) &&
           VerifyField<uint8_t>(verifier, VT_DENORMALIZE, 1) &&
           VerifyField<float>(verifier, VT_EPSILON, 4) &&
           verifier.EndTable();
  }
  NormalizeT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NormalizeT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Normalize> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NormalizeT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NormalizeBuilder {
  typedef Normalize Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_means(flatbuffers::Offset<flatbuffers::Vector<float>> means) {
    fbb_.AddOffset(Normalize::VT_MEANS, means);
  }
  void add_stds(flatbuffers::Offset<flatbuffers::Vector<float>> stds) {
    fbb_.AddOffset(Normalize::VT_STDS, stds);
  }
  void add_denormalize(bool denormalize) {
    fbb_.AddElement<uint8_t>(Normalize::VT_DENORMALIZE, static_cast<uint8_t>(denormalize), 0);
  }
  void add_epsilon(float epsilon) {
    fbb_.AddElement<float>(Normalize::VT_EPSILON, epsilon, 0.00001f);
  }
  explicit NormalizeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Normalize> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Normalize>(end);
    return o;
  }
};

inline flatbuffers::Offset<Normalize> CreateNormalize(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<float>> means = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> stds = 0,
    bool denormalize = false,
    float epsilon = 0.00001f) {
  NormalizeBuilder builder_(_fbb);
  builder_.add_epsilon(epsilon);
  builder_.add_stds(stds);
  builder_.add_means(means);
  builder_.add_denormalize(denormalize);
  return builder_.Finish();
}

inline flatbuffers::Offset<Normalize> CreateNormalizeDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<float> *means = nullptr,
    const std::vector<float> *stds = nullptr,
    bool denormalize = false,
    float epsilon = 0.00001f) {
  auto means__ = means ? _fbb.CreateVector<float>(*means) : 0;
  auto stds__ = stds ? _fbb.CreateVector<float>(*stds) : 0;
  return wnn::CreateNormalize(
      _fbb,
      means__,
      stds__,
      denormalize,
      epsilon);
}

flatbuffers::Offset<Normalize> CreateNormalize(flatbuffers::FlatBufferBuilder &_fbb, const NormalizeT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct FilmLPNT : public flatbuffers::NativeTable {
  typedef FilmLPN TableType;
  int32_t in_features = 0;
  int32_t out_features = 0;
  int32_t input_n = 1;
  int32_t weight_size = 0;
  std::vector<float> weights{};
  std::vector<float> bias{};
  int32_t bias_size = 0;
  std::vector<std::unique_ptr<wnn::QuantT>> quant_param{};
  FilmLPNT() = default;
  FilmLPNT(const FilmLPNT &o);
  FilmLPNT(FilmLPNT&&) FLATBUFFERS_NOEXCEPT = default;
  FilmLPNT &operator=(FilmLPNT o) FLATBUFFERS_NOEXCEPT;
};

struct FilmLPN FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef FilmLPNT NativeTableType;
  typedef FilmLPNBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return FilmLPNTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_IN_FEATURES = 4,
    VT_OUT_FEATURES = 6,
    VT_INPUT_N = 8,
    VT_WEIGHT_SIZE = 10,
    VT_WEIGHTS = 12,
    VT_BIAS = 14,
    VT_BIAS_SIZE = 16,
    VT_QUANT_PARAM = 18
  };
  int32_t in_features() const {
    return GetField<int32_t>(VT_IN_FEATURES, 0);
  }
  int32_t out_features() const {
    return GetField<int32_t>(VT_OUT_FEATURES, 0);
  }
  int32_t input_n() const {
    return GetField<int32_t>(VT_INPUT_N, 1);
  }
  int32_t weight_size() const {
    return GetField<int32_t>(VT_WEIGHT_SIZE, 0);
  }
  const flatbuffers::Vector<float> *weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_WEIGHTS);
  }
  const flatbuffers::Vector<float> *bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_BIAS);
  }
  int32_t bias_size() const {
    return GetField<int32_t>(VT_BIAS_SIZE, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<wnn::Quant>> *quant_param() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<wnn::Quant>> *>(VT_QUANT_PARAM);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_IN_FEATURES, 4) &&
           VerifyField<int32_t>(verifier, VT_OUT_FEATURES, 4) &&
           VerifyField<int32_t>(verifier, VT_INPUT_N, 4) &&
           VerifyField<int32_t>(verifier, VT_WEIGHT_SIZE, 4) &&
           VerifyOffset(verifier, VT_WEIGHTS) &&
           verifier.VerifyVector(weights()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyVector(bias()) &&
           VerifyField<int32_t>(verifier, VT_BIAS_SIZE, 4) &&
           VerifyOffset(verifier, VT_QUANT_PARAM) &&
           verifier.VerifyVector(quant_param()) &&
           verifier.VerifyVectorOfTables(quant_param()) &&
           verifier.EndTable();
  }
  FilmLPNT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(FilmLPNT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<FilmLPN> Pack(flatbuffers::FlatBufferBuilder &_fbb, const FilmLPNT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct FilmLPNBuilder {
  typedef FilmLPN Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_in_features(int32_t in_features) {
    fbb_.AddElement<int32_t>(FilmLPN::VT_IN_FEATURES, in_features, 0);
  }
  void add_out_features(int32_t out_features) {
    fbb_.AddElement<int32_t>(FilmLPN::VT_OUT_FEATURES, out_features, 0);
  }
  void add_input_n(int32_t input_n) {
    fbb_.AddElement<int32_t>(FilmLPN::VT_INPUT_N, input_n, 1);
  }
  void add_weight_size(int32_t weight_size) {
    fbb_.AddElement<int32_t>(FilmLPN::VT_WEIGHT_SIZE, weight_size, 0);
  }
  void add_weights(flatbuffers::Offset<flatbuffers::Vector<float>> weights) {
    fbb_.AddOffset(FilmLPN::VT_WEIGHTS, weights);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::Vector<float>> bias) {
    fbb_.AddOffset(FilmLPN::VT_BIAS, bias);
  }
  void add_bias_size(int32_t bias_size) {
    fbb_.AddElement<int32_t>(FilmLPN::VT_BIAS_SIZE, bias_size, 0);
  }
  void add_quant_param(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<wnn::Quant>>> quant_param) {
    fbb_.AddOffset(FilmLPN::VT_QUANT_PARAM, quant_param);
  }
  explicit FilmLPNBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<FilmLPN> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FilmLPN>(end);
    return o;
  }
};

inline flatbuffers::Offset<FilmLPN> CreateFilmLPN(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t in_features = 0,
    int32_t out_features = 0,
    int32_t input_n = 1,
    int32_t weight_size = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> bias = 0,
    int32_t bias_size = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<wnn::Quant>>> quant_param = 0) {
  FilmLPNBuilder builder_(_fbb);
  builder_.add_quant_param(quant_param);
  builder_.add_bias_size(bias_size);
  builder_.add_bias(bias);
  builder_.add_weights(weights);
  builder_.add_weight_size(weight_size);
  builder_.add_input_n(input_n);
  builder_.add_out_features(out_features);
  builder_.add_in_features(in_features);
  return builder_.Finish();
}

inline flatbuffers::Offset<FilmLPN> CreateFilmLPNDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t in_features = 0,
    int32_t out_features = 0,
    int32_t input_n = 1,
    int32_t weight_size = 0,
    const std::vector<float> *weights = nullptr,
    const std::vector<float> *bias = nullptr,
    int32_t bias_size = 0,
    const std::vector<flatbuffers::Offset<wnn::Quant>> *quant_param = nullptr) {
  auto weights__ = weights ? _fbb.CreateVector<float>(*weights) : 0;
  auto bias__ = bias ? _fbb.CreateVector<float>(*bias) : 0;
  auto quant_param__ = quant_param ? _fbb.CreateVector<flatbuffers::Offset<wnn::Quant>>(*quant_param) : 0;
  return wnn::CreateFilmLPN(
      _fbb,
      in_features,
      out_features,
      input_n,
      weight_size,
      weights__,
      bias__,
      bias_size,
      quant_param__);
}

flatbuffers::Offset<FilmLPN> CreateFilmLPN(flatbuffers::FlatBufferBuilder &_fbb, const FilmLPNT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct CubicT : public flatbuffers::NativeTable {
  typedef Cubic TableType;
  int32_t in_features = 0;
  int32_t out_features = 0;
  int32_t input_n = 1;
  bool merge_matmul = true;
  int32_t weight_size = 0;
  std::vector<float> weight{};
  std::vector<float> bias{};
  int32_t bias_size = 0;
  std::unique_ptr<wnn::QuantT> quant_param{};
  CubicT() = default;
  CubicT(const CubicT &o);
  CubicT(CubicT&&) FLATBUFFERS_NOEXCEPT = default;
  CubicT &operator=(CubicT o) FLATBUFFERS_NOEXCEPT;
};

struct Cubic FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef CubicT NativeTableType;
  typedef CubicBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return CubicTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_IN_FEATURES = 4,
    VT_OUT_FEATURES = 6,
    VT_INPUT_N = 8,
    VT_MERGE_MATMUL = 10,
    VT_WEIGHT_SIZE = 12,
    VT_WEIGHT = 14,
    VT_BIAS = 16,
    VT_BIAS_SIZE = 18,
    VT_QUANT_PARAM = 20
  };
  int32_t in_features() const {
    return GetField<int32_t>(VT_IN_FEATURES, 0);
  }
  int32_t out_features() const {
    return GetField<int32_t>(VT_OUT_FEATURES, 0);
  }
  int32_t input_n() const {
    return GetField<int32_t>(VT_INPUT_N, 1);
  }
  bool merge_matmul() const {
    return GetField<uint8_t>(VT_MERGE_MATMUL, 1) != 0;
  }
  int32_t weight_size() const {
    return GetField<int32_t>(VT_WEIGHT_SIZE, 0);
  }
  const flatbuffers::Vector<float> *weight() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_WEIGHT);
  }
  const flatbuffers::Vector<float> *bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_BIAS);
  }
  int32_t bias_size() const {
    return GetField<int32_t>(VT_BIAS_SIZE, 0);
  }
  const wnn::Quant *quant_param() const {
    return GetPointer<const wnn::Quant *>(VT_QUANT_PARAM);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_IN_FEATURES, 4) &&
           VerifyField<int32_t>(verifier, VT_OUT_FEATURES, 4) &&
           VerifyField<int32_t>(verifier, VT_INPUT_N, 4) &&
           VerifyField<uint8_t>(verifier, VT_MERGE_MATMUL, 1) &&
           VerifyField<int32_t>(verifier, VT_WEIGHT_SIZE, 4) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyVector(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyVector(bias()) &&
           VerifyField<int32_t>(verifier, VT_BIAS_SIZE, 4) &&
           VerifyOffset(verifier, VT_QUANT_PARAM) &&
           verifier.VerifyTable(quant_param()) &&
           verifier.EndTable();
  }
  CubicT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(CubicT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Cubic> Pack(flatbuffers::FlatBufferBuilder &_fbb, const CubicT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct CubicBuilder {
  typedef Cubic Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_in_features(int32_t in_features) {
    fbb_.AddElement<int32_t>(Cubic::VT_IN_FEATURES, in_features, 0);
  }
  void add_out_features(int32_t out_features) {
    fbb_.AddElement<int32_t>(Cubic::VT_OUT_FEATURES, out_features, 0);
  }
  void add_input_n(int32_t input_n) {
    fbb_.AddElement<int32_t>(Cubic::VT_INPUT_N, input_n, 1);
  }
  void add_merge_matmul(bool merge_matmul) {
    fbb_.AddElement<uint8_t>(Cubic::VT_MERGE_MATMUL, static_cast<uint8_t>(merge_matmul), 1);
  }
  void add_weight_size(int32_t weight_size) {
    fbb_.AddElement<int32_t>(Cubic::VT_WEIGHT_SIZE, weight_size, 0);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::Vector<float>> weight) {
    fbb_.AddOffset(Cubic::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::Vector<float>> bias) {
    fbb_.AddOffset(Cubic::VT_BIAS, bias);
  }
  void add_bias_size(int32_t bias_size) {
    fbb_.AddElement<int32_t>(Cubic::VT_BIAS_SIZE, bias_size, 0);
  }
  void add_quant_param(flatbuffers::Offset<wnn::Quant> quant_param) {
    fbb_.AddOffset(Cubic::VT_QUANT_PARAM, quant_param);
  }
  explicit CubicBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<Cubic> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Cubic>(end);
    return o;
  }
};

inline flatbuffers::Offset<Cubic> CreateCubic(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t in_features = 0,
    int32_t out_features = 0,
    int32_t input_n = 1,
    bool merge_matmul = true,
    int32_t weight_size = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> weight = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> bias = 0,
    int32_t bias_size = 0,
    flatbuffers::Offset<wnn::Quant> quant_param = 0) {
  CubicBuilder builder_(_fbb);
  builder_.add_quant_param(quant_param);
  builder_.add_bias_size(bias_size);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_weight_size(weight_size);
  builder_.add_input_n(input_n);
  builder_.add_out_features(out_features);
  builder_.add_in_features(in_features);
  builder_.add_merge_matmul(merge_matmul);
  return builder_.Finish();
}

inline flatbuffers::Offset<Cubic> CreateCubicDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t in_features = 0,
    int32_t out_features = 0,
    int32_t input_n = 1,
    bool merge_matmul = true,
    int32_t weight_size = 0,
    const std::vector<float> *weight = nullptr,
    const std::vector<float> *bias = nullptr,
    int32_t bias_size = 0,
    flatbuffers::Offset<wnn::Quant> quant_param = 0) {
  auto weight__ = weight ? _fbb.CreateVector<float>(*weight) : 0;
  auto bias__ = bias ? _fbb.CreateVector<float>(*bias) : 0;
  return wnn::CreateCubic(
      _fbb,
      in_features,
      out_features,
      input_n,
      merge_matmul,
      weight_size,
      weight__,
      bias__,
      bias_size,
      quant_param);
}

flatbuffers::Offset<Cubic> CreateCubic(flatbuffers::FlatBufferBuilder &_fbb, const CubicT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct MultiHeadAttentionT : public flatbuffers::NativeTable {
  typedef MultiHeadAttention TableType;
  int32_t embed_dim = 0;
  int32_t num_heads = 0;
  bool bias = true;
  int32_t kdim = 0;
  int32_t vdim = 0;
  bool batch_first = false;
  bool relative_pos = false;
  std::vector<float> q_weights{};
  std::vector<float> q_bias{};
  std::vector<float> k_weights{};
  std::vector<float> k_bias{};
  std::vector<float> v_weights{};
  std::vector<float> v_bias{};
  std::vector<float> out_weights{};
  std::vector<float> out_bias{};
  std::vector<float> in_weights{};
  std::vector<float> in_bias{};
};

struct MultiHeadAttention FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef MultiHeadAttentionT NativeTableType;
  typedef MultiHeadAttentionBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return MultiHeadAttentionTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_EMBED_DIM = 4,
    VT_NUM_HEADS = 6,
    VT_BIAS = 8,
    VT_KDIM = 10,
    VT_VDIM = 12,
    VT_BATCH_FIRST = 14,
    VT_RELATIVE_POS = 16,
    VT_Q_WEIGHTS = 18,
    VT_Q_BIAS = 20,
    VT_K_WEIGHTS = 22,
    VT_K_BIAS = 24,
    VT_V_WEIGHTS = 26,
    VT_V_BIAS = 28,
    VT_OUT_WEIGHTS = 30,
    VT_OUT_BIAS = 32,
    VT_IN_WEIGHTS = 34,
    VT_IN_BIAS = 36
  };
  int32_t embed_dim() const {
    return GetField<int32_t>(VT_EMBED_DIM, 0);
  }
  int32_t num_heads() const {
    return GetField<int32_t>(VT_NUM_HEADS, 0);
  }
  bool bias() const {
    return GetField<uint8_t>(VT_BIAS, 1) != 0;
  }
  int32_t kdim() const {
    return GetField<int32_t>(VT_KDIM, 0);
  }
  int32_t vdim() const {
    return GetField<int32_t>(VT_VDIM, 0);
  }
  bool batch_first() const {
    return GetField<uint8_t>(VT_BATCH_FIRST, 0) != 0;
  }
  bool relative_pos() const {
    return GetField<uint8_t>(VT_RELATIVE_POS, 0) != 0;
  }
  const flatbuffers::Vector<float> *q_weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_Q_WEIGHTS);
  }
  const flatbuffers::Vector<float> *q_bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_Q_BIAS);
  }
  const flatbuffers::Vector<float> *k_weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_K_WEIGHTS);
  }
  const flatbuffers::Vector<float> *k_bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_K_BIAS);
  }
  const flatbuffers::Vector<float> *v_weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_V_WEIGHTS);
  }
  const flatbuffers::Vector<float> *v_bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_V_BIAS);
  }
  const flatbuffers::Vector<float> *out_weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_OUT_WEIGHTS);
  }
  const flatbuffers::Vector<float> *out_bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_OUT_BIAS);
  }
  const flatbuffers::Vector<float> *in_weights() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_IN_WEIGHTS);
  }
  const flatbuffers::Vector<float> *in_bias() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_IN_BIAS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_EMBED_DIM, 4) &&
           VerifyField<int32_t>(verifier, VT_NUM_HEADS, 4) &&
           VerifyField<uint8_t>(verifier, VT_BIAS, 1) &&
           VerifyField<int32_t>(verifier, VT_KDIM, 4) &&
           VerifyField<int32_t>(verifier, VT_VDIM, 4) &&
           VerifyField<uint8_t>(verifier, VT_BATCH_FIRST, 1) &&
           VerifyField<uint8_t>(verifier, VT_RELATIVE_POS, 1) &&
           VerifyOffset(verifier, VT_Q_WEIGHTS) &&
           verifier.VerifyVector(q_weights()) &&
           VerifyOffset(verifier, VT_Q_BIAS) &&
           verifier.VerifyVector(q_bias()) &&
           VerifyOffset(verifier, VT_K_WEIGHTS) &&
           verifier.VerifyVector(k_weights()) &&
           VerifyOffset(verifier, VT_K_BIAS) &&
           verifier.VerifyVector(k_bias()) &&
           VerifyOffset(verifier, VT_V_WEIGHTS) &&
           verifier.VerifyVector(v_weights()) &&
           VerifyOffset(verifier, VT_V_BIAS) &&
           verifier.VerifyVector(v_bias()) &&
           VerifyOffset(verifier, VT_OUT_WEIGHTS) &&
           verifier.VerifyVector(out_weights()) &&
           VerifyOffset(verifier, VT_OUT_BIAS) &&
           verifier.VerifyVector(out_bias()) &&
           VerifyOffset(verifier, VT_IN_WEIGHTS) &&
           verifier.VerifyVector(in_weights()) &&
           VerifyOffset(verifier, VT_IN_BIAS) &&
           verifier.VerifyVector(in_bias()) &&
           verifier.EndTable();
  }
  MultiHeadAttentionT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(MultiHeadAttentionT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<MultiHeadAttention> Pack(flatbuffers::FlatBufferBuilder &_fbb, const MultiHeadAttentionT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct MultiHeadAttentionBuilder {
  typedef MultiHeadAttention Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_embed_dim(int32_t embed_dim) {
    fbb_.AddElement<int32_t>(MultiHeadAttention::VT_EMBED_DIM, embed_dim, 0);
  }
  void add_num_heads(int32_t num_heads) {
    fbb_.AddElement<int32_t>(MultiHeadAttention::VT_NUM_HEADS, num_heads, 0);
  }
  void add_bias(bool bias) {
    fbb_.AddElement<uint8_t>(MultiHeadAttention::VT_BIAS, static_cast<uint8_t>(bias), 1);
  }
  void add_kdim(int32_t kdim) {
    fbb_.AddElement<int32_t>(MultiHeadAttention::VT_KDIM, kdim, 0);
  }
  void add_vdim(int32_t vdim) {
    fbb_.AddElement<int32_t>(MultiHeadAttention::VT_VDIM, vdim, 0);
  }
  void add_batch_first(bool batch_first) {
    fbb_.AddElement<uint8_t>(MultiHeadAttention::VT_BATCH_FIRST, static_cast<uint8_t>(batch_first), 0);
  }
  void add_relative_pos(bool relative_pos) {
    fbb_.AddElement<uint8_t>(MultiHeadAttention::VT_RELATIVE_POS, static_cast<uint8_t>(relative_pos), 0);
  }
  void add_q_weights(flatbuffers::Offset<flatbuffers::Vector<float>> q_weights) {
    fbb_.AddOffset(MultiHeadAttention::VT_Q_WEIGHTS, q_weights);
  }
  void add_q_bias(flatbuffers::Offset<flatbuffers::Vector<float>> q_bias) {
    fbb_.AddOffset(MultiHeadAttention::VT_Q_BIAS, q_bias);
  }
  void add_k_weights(flatbuffers::Offset<flatbuffers::Vector<float>> k_weights) {
    fbb_.AddOffset(MultiHeadAttention::VT_K_WEIGHTS, k_weights);
  }
  void add_k_bias(flatbuffers::Offset<flatbuffers::Vector<float>> k_bias) {
    fbb_.AddOffset(MultiHeadAttention::VT_K_BIAS, k_bias);
  }
  void add_v_weights(flatbuffers::Offset<flatbuffers::Vector<float>> v_weights) {
    fbb_.AddOffset(MultiHeadAttention::VT_V_WEIGHTS, v_weights);
  }
  void add_v_bias(flatbuffers::Offset<flatbuffers::Vector<float>> v_bias) {
    fbb_.AddOffset(MultiHeadAttention::VT_V_BIAS, v_bias);
  }
  void add_out_weights(flatbuffers::Offset<flatbuffers::Vector<float>> out_weights) {
    fbb_.AddOffset(MultiHeadAttention::VT_OUT_WEIGHTS, out_weights);
  }
  void add_out_bias(flatbuffers::Offset<flatbuffers::Vector<float>> out_bias) {
    fbb_.AddOffset(MultiHeadAttention::VT_OUT_BIAS, out_bias);
  }
  void add_in_weights(flatbuffers::Offset<flatbuffers::Vector<float>> in_weights) {
    fbb_.AddOffset(MultiHeadAttention::VT_IN_WEIGHTS, in_weights);
  }
  void add_in_bias(flatbuffers::Offset<flatbuffers::Vector<float>> in_bias) {
    fbb_.AddOffset(MultiHeadAttention::VT_IN_BIAS, in_bias);
  }
  explicit MultiHeadAttentionBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  flatbuffers::Offset<MultiHeadAttention> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MultiHeadAttention>(end);
    return o;
  }
};

inline flatbuffers::Offset<MultiHeadAttention> CreateMultiHeadAttention(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t embed_dim = 0,
    int32_t num_heads = 0,
    bool bias = true,
    int32_t kdim = 0,
    int32_t vdim = 0,
    bool batch_first = false,
    bool relative_pos = false,
    flatbuffers::Offset<flatbuffers::Vector<float>> q_weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> q_bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> k_weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> k_bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> v_weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> v_bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> out_weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> out_bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> in_weights = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> in_bias = 0) {
  MultiHeadAttentionBuilder builder_(_fbb);
  builder_.add_in_bias(in_bias);
  builder_.add_in_weights(in_weights);
  builder_.add_out_bias(out_bias);
  builder_.add_out_weights(out_weights);
  builder_.add_v_bias(v_bias);
  builder_.add_v_weights(v_weights);
  builder_.add_k_bias(k_bias);
  builder_.add_k_weights(k_weights);
  builder_.add_q_bias(q_bias);
  builder_.add_q_weights(q_weights);
  builder_.add_vdim(vdim);
  builder_.add_kdim(kdim);
  builder_.add_num_heads(num_heads);
  builder_.add_embed_dim(embed_dim);
  builder_.add_relative_pos(relative_pos);
  builder_.add_batch_first(batch_first);
  builder_.add_bias(bias);
  return builder_.Finish();
}

inline flatbuffers::Offset<MultiHeadAttention> CreateMultiHeadAttentionDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t embed_dim = 0,
    int32_t num_heads = 0,
    bool bias = true,
    int32_t kdim = 0,
    int32_t vdim = 0,
    bool batch_first = false,
    bool relative_pos = false,
    const std::vector<float> *q_weights = nullptr,
    const std::vector<float> *q_bias = nullptr,
    const std::vector<float> *k_weights = nullptr,
    const std::vector<float> *k_bias = nullptr,
    const std::vector<float> *v_weights = nullptr,
    const std::vector<float> *v_bias = nullptr,
    const std::vector<float> *out_weights = nullptr,
    const std::vector<float> *out_bias = nullptr,
    const std::vector<float> *in_weights = nullptr,
    const std::vector<float> *in_bias = nullptr) {
  auto q_weights__ = q_weights ? _fbb.CreateVector<float>(*q_weights) : 0;
  auto q_bias__ = q_bias ? _fbb.CreateVector<float>(*q_bias) : 0;
  auto k_weights__ = k_weights ? _fbb.CreateVector<float>(*k_weights) : 0;
  auto k_bias__ = k_bias ? _fbb.CreateVector<float>(*k_bias) : 0;
  auto v_weights__ = v_weights ? _fbb.CreateVector<float>(*v_weights) : 0;
  auto v_bias__ = v_bias ? _fbb.CreateVector<float>(*v_bias) : 0;
  auto out_weights__ = out_weights ? _fbb.CreateVector<float>(*out_weights) : 0;
  auto out_bias__ = out_bias ? _fbb.CreateVector<float>(*out_bias) : 0;
  auto in_weights__ = in_weights ? _fbb.CreateVector<float>(*in_weights) : 0;
  auto in_bias__ = in_bias ? _fbb.CreateVector<float>(*in_bias) : 0;
  return wnn::CreateMultiHeadAttention(
      _fbb,
      embed_dim,
      num_heads,
      bias,
      kdim,
      vdim,
      batch_first,
      relative_pos,
      q_weights__,
      q_bias__,
      k_weights__,
      k_bias__,
      v_weights__,
      v_bias__,
      out_weights__,
      out_bias__,
      in_weights__,
      in_bias__);
}

flatbuffers::Offset<MultiHeadAttention> CreateMultiHeadAttention(flatbuffers::FlatBufferBuilder &_fbb, const MultiHeadAttentionT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline NormalizeT *Normalize::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<NormalizeT>(new NormalizeT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Normalize::UnPackTo(NormalizeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = means(); if (_e) { _o->means.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->means[_i] = _e->Get(_i); } } }
  { auto _e = stds(); if (_e) { _o->stds.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stds[_i] = _e->Get(_i); } } }
  { auto _e = denormalize(); _o->denormalize = _e; }
  { auto _e = epsilon(); _o->epsilon = _e; }
}

inline flatbuffers::Offset<Normalize> Normalize::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NormalizeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNormalize(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Normalize> CreateNormalize(flatbuffers::FlatBufferBuilder &_fbb, const NormalizeT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NormalizeT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _means = _o->means.size() ? _fbb.CreateVector(_o->means) : 0;
  auto _stds = _o->stds.size() ? _fbb.CreateVector(_o->stds) : 0;
  auto _denormalize = _o->denormalize;
  auto _epsilon = _o->epsilon;
  return wnn::CreateNormalize(
      _fbb,
      _means,
      _stds,
      _denormalize,
      _epsilon);
}

inline FilmLPNT::FilmLPNT(const FilmLPNT &o)
      : in_features(o.in_features),
        out_features(o.out_features),
        input_n(o.input_n),
        weight_size(o.weight_size),
        weights(o.weights),
        bias(o.bias),
        bias_size(o.bias_size) {
  quant_param.reserve(o.quant_param.size());
  for (const auto &quant_param_ : o.quant_param) { quant_param.emplace_back((quant_param_) ? new wnn::QuantT(*quant_param_) : nullptr); }
}

inline FilmLPNT &FilmLPNT::operator=(FilmLPNT o) FLATBUFFERS_NOEXCEPT {
  std::swap(in_features, o.in_features);
  std::swap(out_features, o.out_features);
  std::swap(input_n, o.input_n);
  std::swap(weight_size, o.weight_size);
  std::swap(weights, o.weights);
  std::swap(bias, o.bias);
  std::swap(bias_size, o.bias_size);
  std::swap(quant_param, o.quant_param);
  return *this;
}

inline FilmLPNT *FilmLPN::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<FilmLPNT>(new FilmLPNT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void FilmLPN::UnPackTo(FilmLPNT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = in_features(); _o->in_features = _e; }
  { auto _e = out_features(); _o->out_features = _e; }
  { auto _e = input_n(); _o->input_n = _e; }
  { auto _e = weight_size(); _o->weight_size = _e; }
  { auto _e = weights(); if (_e) { _o->weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weights[_i] = _e->Get(_i); } } }
  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
  { auto _e = bias_size(); _o->bias_size = _e; }
  { auto _e = quant_param(); if (_e) { _o->quant_param.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { if(_o->quant_param[_i]) { _e->Get(_i)->UnPackTo(_o->quant_param[_i].get(), _resolver); } else { _o->quant_param[_i] = std::unique_ptr<wnn::QuantT>(_e->Get(_i)->UnPack(_resolver)); }; } } }
}

inline flatbuffers::Offset<FilmLPN> FilmLPN::Pack(flatbuffers::FlatBufferBuilder &_fbb, const FilmLPNT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateFilmLPN(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<FilmLPN> CreateFilmLPN(flatbuffers::FlatBufferBuilder &_fbb, const FilmLPNT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const FilmLPNT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _in_features = _o->in_features;
  auto _out_features = _o->out_features;
  auto _input_n = _o->input_n;
  auto _weight_size = _o->weight_size;
  auto _weights = _o->weights.size() ? _fbb.CreateVector(_o->weights) : 0;
  auto _bias = _o->bias.size() ? _fbb.CreateVector(_o->bias) : 0;
  auto _bias_size = _o->bias_size;
  auto _quant_param = _o->quant_param.size() ? _fbb.CreateVector<flatbuffers::Offset<wnn::Quant>> (_o->quant_param.size(), [](size_t i, _VectorArgs *__va) { return CreateQuant(*__va->__fbb, __va->__o->quant_param[i].get(), __va->__rehasher); }, &_va ) : 0;
  return wnn::CreateFilmLPN(
      _fbb,
      _in_features,
      _out_features,
      _input_n,
      _weight_size,
      _weights,
      _bias,
      _bias_size,
      _quant_param);
}

inline CubicT::CubicT(const CubicT &o)
      : in_features(o.in_features),
        out_features(o.out_features),
        input_n(o.input_n),
        merge_matmul(o.merge_matmul),
        weight_size(o.weight_size),
        weight(o.weight),
        bias(o.bias),
        bias_size(o.bias_size),
        quant_param((o.quant_param) ? new wnn::QuantT(*o.quant_param) : nullptr) {
}

inline CubicT &CubicT::operator=(CubicT o) FLATBUFFERS_NOEXCEPT {
  std::swap(in_features, o.in_features);
  std::swap(out_features, o.out_features);
  std::swap(input_n, o.input_n);
  std::swap(merge_matmul, o.merge_matmul);
  std::swap(weight_size, o.weight_size);
  std::swap(weight, o.weight);
  std::swap(bias, o.bias);
  std::swap(bias_size, o.bias_size);
  std::swap(quant_param, o.quant_param);
  return *this;
}

inline CubicT *Cubic::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<CubicT>(new CubicT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Cubic::UnPackTo(CubicT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = in_features(); _o->in_features = _e; }
  { auto _e = out_features(); _o->out_features = _e; }
  { auto _e = input_n(); _o->input_n = _e; }
  { auto _e = merge_matmul(); _o->merge_matmul = _e; }
  { auto _e = weight_size(); _o->weight_size = _e; }
  { auto _e = weight(); if (_e) { _o->weight.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->weight[_i] = _e->Get(_i); } } }
  { auto _e = bias(); if (_e) { _o->bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->bias[_i] = _e->Get(_i); } } }
  { auto _e = bias_size(); _o->bias_size = _e; }
  { auto _e = quant_param(); if (_e) { if(_o->quant_param) { _e->UnPackTo(_o->quant_param.get(), _resolver); } else { _o->quant_param = std::unique_ptr<wnn::QuantT>(_e->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<Cubic> Cubic::Pack(flatbuffers::FlatBufferBuilder &_fbb, const CubicT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateCubic(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Cubic> CreateCubic(flatbuffers::FlatBufferBuilder &_fbb, const CubicT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const CubicT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _in_features = _o->in_features;
  auto _out_features = _o->out_features;
  auto _input_n = _o->input_n;
  auto _merge_matmul = _o->merge_matmul;
  auto _weight_size = _o->weight_size;
  auto _weight = _o->weight.size() ? _fbb.CreateVector(_o->weight) : 0;
  auto _bias = _o->bias.size() ? _fbb.CreateVector(_o->bias) : 0;
  auto _bias_size = _o->bias_size;
  auto _quant_param = _o->quant_param ? CreateQuant(_fbb, _o->quant_param.get(), _rehasher) : 0;
  return wnn::CreateCubic(
      _fbb,
      _in_features,
      _out_features,
      _input_n,
      _merge_matmul,
      _weight_size,
      _weight,
      _bias,
      _bias_size,
      _quant_param);
}

inline MultiHeadAttentionT *MultiHeadAttention::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<MultiHeadAttentionT>(new MultiHeadAttentionT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void MultiHeadAttention::UnPackTo(MultiHeadAttentionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = embed_dim(); _o->embed_dim = _e; }
  { auto _e = num_heads(); _o->num_heads = _e; }
  { auto _e = bias(); _o->bias = _e; }
  { auto _e = kdim(); _o->kdim = _e; }
  { auto _e = vdim(); _o->vdim = _e; }
  { auto _e = batch_first(); _o->batch_first = _e; }
  { auto _e = relative_pos(); _o->relative_pos = _e; }
  { auto _e = q_weights(); if (_e) { _o->q_weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->q_weights[_i] = _e->Get(_i); } } }
  { auto _e = q_bias(); if (_e) { _o->q_bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->q_bias[_i] = _e->Get(_i); } } }
  { auto _e = k_weights(); if (_e) { _o->k_weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->k_weights[_i] = _e->Get(_i); } } }
  { auto _e = k_bias(); if (_e) { _o->k_bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->k_bias[_i] = _e->Get(_i); } } }
  { auto _e = v_weights(); if (_e) { _o->v_weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->v_weights[_i] = _e->Get(_i); } } }
  { auto _e = v_bias(); if (_e) { _o->v_bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->v_bias[_i] = _e->Get(_i); } } }
  { auto _e = out_weights(); if (_e) { _o->out_weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->out_weights[_i] = _e->Get(_i); } } }
  { auto _e = out_bias(); if (_e) { _o->out_bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->out_bias[_i] = _e->Get(_i); } } }
  { auto _e = in_weights(); if (_e) { _o->in_weights.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->in_weights[_i] = _e->Get(_i); } } }
  { auto _e = in_bias(); if (_e) { _o->in_bias.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->in_bias[_i] = _e->Get(_i); } } }
}

inline flatbuffers::Offset<MultiHeadAttention> MultiHeadAttention::Pack(flatbuffers::FlatBufferBuilder &_fbb, const MultiHeadAttentionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateMultiHeadAttention(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<MultiHeadAttention> CreateMultiHeadAttention(flatbuffers::FlatBufferBuilder &_fbb, const MultiHeadAttentionT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const MultiHeadAttentionT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _embed_dim = _o->embed_dim;
  auto _num_heads = _o->num_heads;
  auto _bias = _o->bias;
  auto _kdim = _o->kdim;
  auto _vdim = _o->vdim;
  auto _batch_first = _o->batch_first;
  auto _relative_pos = _o->relative_pos;
  auto _q_weights = _o->q_weights.size() ? _fbb.CreateVector(_o->q_weights) : 0;
  auto _q_bias = _o->q_bias.size() ? _fbb.CreateVector(_o->q_bias) : 0;
  auto _k_weights = _o->k_weights.size() ? _fbb.CreateVector(_o->k_weights) : 0;
  auto _k_bias = _o->k_bias.size() ? _fbb.CreateVector(_o->k_bias) : 0;
  auto _v_weights = _o->v_weights.size() ? _fbb.CreateVector(_o->v_weights) : 0;
  auto _v_bias = _o->v_bias.size() ? _fbb.CreateVector(_o->v_bias) : 0;
  auto _out_weights = _o->out_weights.size() ? _fbb.CreateVector(_o->out_weights) : 0;
  auto _out_bias = _o->out_bias.size() ? _fbb.CreateVector(_o->out_bias) : 0;
  auto _in_weights = _o->in_weights.size() ? _fbb.CreateVector(_o->in_weights) : 0;
  auto _in_bias = _o->in_bias.size() ? _fbb.CreateVector(_o->in_bias) : 0;
  return wnn::CreateMultiHeadAttention(
      _fbb,
      _embed_dim,
      _num_heads,
      _bias,
      _kdim,
      _vdim,
      _batch_first,
      _relative_pos,
      _q_weights,
      _q_bias,
      _k_weights,
      _k_bias,
      _v_weights,
      _v_bias,
      _out_weights,
      _out_bias,
      _in_weights,
      _in_bias);
}

inline const flatbuffers::TypeTable *ImageFormatTypeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    wnn::ImageFormatTypeTypeTable
  };
  static const char * const names[] = {
    "RGBA",
    "RGB",
    "BGR",
    "GRAY",
    "YUV",
    "HSV"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 6, type_codes, type_refs, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *FilterTypeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    wnn::FilterTypeTypeTable
  };
  static const char * const names[] = {
    "NEAREST",
    "BILINEAR",
    "BICUBIC"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NormalizeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_FLOAT, 0, -1 }
  };
  static const char * const names[] = {
    "means",
    "stds",
    "denormalize",
    "epsilon"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, nullptr, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *FilmLPNTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    wnn::QuantTypeTable
  };
  static const char * const names[] = {
    "in_features",
    "out_features",
    "input_n",
    "weight_size",
    "weights",
    "bias",
    "bias_size",
    "quant_param"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 8, type_codes, type_refs, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *CubicTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    wnn::QuantTypeTable
  };
  static const char * const names[] = {
    "in_features",
    "out_features",
    "input_n",
    "merge_matmul",
    "weight_size",
    "weight",
    "bias",
    "bias_size",
    "quant_param"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 9, type_codes, type_refs, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *MultiHeadAttentionTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_BOOL, 0, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 },
    { flatbuffers::ET_FLOAT, 1, -1 }
  };
  static const char * const names[] = {
    "embed_dim",
    "num_heads",
    "bias",
    "kdim",
    "vdim",
    "batch_first",
    "relative_pos",
    "q_weights",
    "q_bias",
    "k_weights",
    "k_bias",
    "v_weights",
    "v_bias",
    "out_weights",
    "out_bias",
    "in_weights",
    "in_bias"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 17, type_codes, nullptr, nullptr, nullptr, names
  };
  return &tt;
}

}  // namespace wnn

#endif  // FLATBUFFERS_GENERATED_CUSTOMDEFINE_WNN_H_
